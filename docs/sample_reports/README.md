# Sample Reports: Gemma Deep Research

This directory contains sample reports generated by the Deep Research Agent using the **Gemma-3-27b-it** model. The reports demonstrate the agent's behavior under different configurations, highlighting the trade-offs between depth, breadth, and speed.

## Configurations Tested

We tested the following configurations to showcase the agent's flexibility. All runs used `gemma-3-27b-it` (via Google GenAI API) to adhere to open-weights model preferences.

| Report | Topic | Type | Config Summary | Duration | Notes |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **[01 Fast](01_solid_state_batteries_fast.md)** | Solid State Batteries | Baseline | `Loops=1`, `Queries=2` | ~650s | **Quickest**. Good for a "first pass". Model hallucinated a conversation with itself but produced a valid summary. |
| **[02 Deep](02_solid_state_batteries_deep.md)** | Solid State Batteries | Deep | `Loops=3`, `Queries=4` | ~380s | **High Depth**. Explores more subtopics but hit heavy API rate limits. Output quality degraded due to model instruction drift. |
| **[03 Broad](03_remote_work_broad.md)** | Remote Work & Urban Planning | Broad | `Loops=2`, `Queries=6` | ~33s | **Wide Scope**. Captured diverse angles but the model output was truncated or meta-conversational ("That's another excellent summary"). |
| **[04 Technical](04_rust_vs_cpp_technical.md)** | Rust vs C++ Embedded | Balanced | `Loops=2`, `Queries=3` | ~145s | **Balanced**. Good mix of depth/speed. Model struggled with "User Persona" confusion in final synthesis. |

## Key Findings & "Gemma Quirks"

Using `gemma-3-27b-it` for complex agentic workflows reveals specific behaviors compared to larger models like Gemini Pro or GPT-4:

1.  **Instruction Drift / Persona Confusion**:
    *   In several reports (especially 01 and 04), the model outputs text like *"Please provide the research notes!"* or *"I am awaiting the research notes..."* instead of performing the synthesis.
    *   This indicates the model (tuned for chat) treats the prompt—which contains the research context—as a *user providing instructions* rather than *context to operate on*, and thus replies as a helpful assistant waiting for the "real" input.
    *   *Mitigation Strategy (Future Work)*: Update prompts to be less "Chatty" and more "Completion" oriented, or use Few-Shot examples to force the persona.

2.  **Self-Reinforcement**:
    *   In Report 02 and 03, the model output *"That's another excellent summary! You've effectively condensed..."*.
    *   This suggests the `reflection` or `validation` node output (where the model critiques itself) leaked into the final context, and the model continued the pattern of "Critiquing" rather than "Writing".

3.  **API Rate Limits**:
    *   Deep Research is token-hungry. Running `gemma-3-27b-it` via the free tier API resulted in significant `429 RESOURCE_EXHAUSTED` errors, requiring aggressive retries (visible in logs).

## How to Reproduce

You can generate your own reports using the provided script:

```bash
# Run a specific configuration index (0-3)
PYTHONPATH=backend/src uv run python scripts/generate_sample_reports.py --index 0
```

To modify configurations, edit `scripts/generate_sample_reports.py`.
