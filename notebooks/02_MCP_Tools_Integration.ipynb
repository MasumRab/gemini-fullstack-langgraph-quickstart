{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- COLAB SETUP START ---\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # 1. Clone the repository\n",
    "    !git clone https://github.com/MasumRab/gemini-fullstack-langgraph-quickstart\n",
    "    %cd gemini-fullstack-langgraph-quickstart/backend\n",
    "\n",
    "    # 2. Prepare Environment (Resolving Conflicts)\n",
    "    import sys\n",
    "    print(\"Uninstalling conflicting pre-installed packages...\")\n",
    "    !pip uninstall -y google-ai-generativelanguage google-generativeai tensorflow grpcio-status\n",
    "\n",
    "    # Pre-install PyTorch Nightly if Python 3.13+ is detected\n",
    "    if sys.version_info >= (3, 13):\n",
    "        print(\"Detected Python 3.13+. Installing PyTorch Nightly...\")\n",
    "        !pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "\n",
    "    # 3. Install Backend\n",
    "    !pip install .\n",
    "\n",
    "    # 4. Set API Key\n",
    "    import os\n",
    "    from google.colab import userdata\n",
    "    try:\n",
    "        os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
    "    except:\n",
    "        print(\"Please enter your Gemini API Key:\")\n",
    "        os.environ[\"GEMINI_API_KEY\"] = input()\n",
    "# --- COLAB SETUP END ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCP Tools: Planned Tool Use\n",
    "\n",
    "This notebook demonstrates the Model Context Protocol (MCP) integration, specifically:\n",
    "1. Setting up a Filesystem MCP Server\n",
    "2. Planning tool sequences with an LLM\n",
    "3. Executing file operations safely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Add backend/src to path\n",
    "sys.path.append(os.path.abspath(\"../backend/src\"))\n",
    "\n",
    "from agent.mcp_server import FilesystemMCPServer\n",
    "from agent.mcp_client import MCPToolUser\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup MCP Server\n",
    "\n",
    "We create a sandbox directory and initialize the server allowing access only to that directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup sandbox\n",
    "sandbox_dir = \"./mcp_sandbox\"\n",
    "os.makedirs(sandbox_dir, exist_ok=True)\n",
    "\n",
    "# Initialize Server\n",
    "fs_server = FilesystemMCPServer(allowed_paths=[sandbox_dir])\n",
    "print(f\"Filesystem Server initialized. Root: {sandbox_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Tool User (Client)\n",
    "\n",
    "The client aggregates tools from servers and handles planning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp_client = MCPToolUser(mcp_servers=[fs_server])\n",
    "\n",
    "# List available tools\n",
    "print(\"Available Tools:\")\n",
    "for name in mcp_client.tool_registry:\n",
    "    print(f\"- {name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Tool Operations (Manual Test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "async def run_manual_test():\n",
    "    # Write\n",
    "    print(\"Writing file...\")\n",
    "    res = await mcp_client.execute_tool(\n",
    "        \"filesystem.write_file\", \n",
    "        path=f\"{sandbox_dir}/test.txt\", \n",
    "        content=\"Hello MCP World!\"\n",
    "    )\n",
    "    print(\"Write Result:\", res)\n",
    "\n",
    "    # Read\n",
    "    print(\"\\nReading file...\")\n",
    "    res = await mcp_client.execute_tool(\n",
    "        \"filesystem.read_file\", \n",
    "        path=f\"{sandbox_dir}/test.txt\"\n",
    "    )\n",
    "    print(\"Read Result:\", res)\n",
    "\n",
    "await run_manual_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tool Planning Demo\n",
    "\n",
    "We ask the LLM to plan a sequence of operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "try:\n",
    "    llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-pro\", temperature=0)\n",
    "except Exception as e:\n",
    "    print(\"Using Mock LLM\")\n",
    "    class MockLLM:\n",
    "        def invoke(self, prompt): return '```json\\n[{\"tool\": \"filesystem.write_file\", \"params\": {\"path\": \"./mcp_sandbox/plan.txt\", \"content\": \"Step 1: Done\"}}]\\n```'\n",
    "    llm = MockLLM()\n",
    "\n",
    "# Scenario\n",
    "task = f\"Create a new directory named 'reports' inside '{sandbox_dir}' and write a file named 'summary.md' inside it with the text 'Analysis Complete'.\"\n",
    "\n",
    "# 1. Plan\n",
    "plan = mcp_client.plan_tool_sequence(task, llm)\n",
    "print(\"Generated Plan:\")\n",
    "print(json.dumps(plan, indent=2))\n",
    "\n",
    "# 2. Execute\n",
    "print(\"\\nExecuting Plan...\")\n",
    "import json\n",
    "if plan:\n",
    "    results = await mcp_client.execute_plan(plan)\n",
    "    for r in results:\n",
    "        print(f\"Tool: {r['tool']}, Success: {r['result'].get('success')}\")\n",
    "else:\n",
    "    print(\"Plan generation failed or empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Security & Constraints\n",
    "\n",
    "Verify that we cannot write outside the sandbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_security():\n",
    "    print(\"Attempting to write to /tmp (outside sandbox)...\")\n",
    "    res = await mcp_client.execute_tool(\n",
    "        \"filesystem.write_file\", \n",
    "        path=\"/tmp/hacked.txt\", \n",
    "        content=\"Should fail\"\n",
    "    )\n",
    "    print(\"Result:\", res)\n",
    "\n",
    "await test_security()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}