{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- COLAB SETUP START ---\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # 1. Clone the repository\n",
<<<<<<< HEAD
    "    !git clone https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart\n",
=======
    "    !git clone https://github.com/MasumRab/gemini-fullstack-langgraph-quickstart\n",
>>>>>>> origin/main
    "    %cd gemini-fullstack-langgraph-quickstart/backend\n",
    "\n",
    "    # 2. Prepare Environment (Resolving Conflicts)\n",
    "    import sys\n",
    "    print(\"Uninstalling conflicting pre-installed packages...\")\n",
<<<<<<< HEAD
    "    !pip uninstall -y google-ai-generativelanguage tensorflow grpcio-status\n",
=======
    "    !pip uninstall -y google-ai-generativelanguage google-generativeai tensorflow grpcio-status\n",
>>>>>>> origin/main
    "\n",
    "    # Pre-install PyTorch Nightly if Python 3.13+ is detected\n",
    "    if sys.version_info >= (3, 13):\n",
    "        print(\"Detected Python 3.13+. Installing PyTorch Nightly...\")\n",
    "        !pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "\n",
    "    # 3. Install Backend\n",
    "    !pip install .\n",
    "\n",
    "    # 4. Set API Key\n",
    "    import os\n",
    "    from google.colab import userdata\n",
    "    try:\n",
    "        os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
    "    except:\n",
    "        print(\"Please enter your Gemini API Key:\")\n",
    "        os.environ[\"GEMINI_API_KEY\"] = input()\n",
    "# --- COLAB SETUP END ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOTA Framework Comparison\n",
    "\n",
    "This notebook compares our Deep Research Agent architecture against state-of-the-art frameworks:\n",
    "1. **FlowSearch**\n",
    "2. **RhinoInsight**\n",
    "3. **TTD-DR**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Feature Comparison\n",
    "\n",
    "| Feature | Our Agent | FlowSearch | RhinoInsight | TTD-DR |\n",
    "|---------|-----------|------------|--------------|--------|\n",
    "| Architecture | Modular (Nodes) | Pipeline | Checklist | Tree-of-Thought |\n",
    "| RAG Type | Hybrid (Vector+Graph) | Vector Only | Graph Only | Vector |\n",
    "| Evidence Auditing | \u2705 Yes | \u274c No | \u2705 Yes | \u274c No |\n",
    "| Subgoal Verification | \u2705 Yes | \u274c No | \u274c No | \u2705 Yes |\n",
    "| MCP Integration | \u2705 Yes | \u274c No | \u274c No | \u274c No |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Performance Analysis\n",
    "\n",
    "Based on the DeepResearch-Bench metrics calculated in Notebook 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load our results\n",
    "results_path = \"../results/benchmark_run.json\"\n",
    "if os.path.exists(results_path):\n",
    "    with open(results_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        our_scores = data.get(\"final_scores\", {})\n",
    "else:\n",
    "    # Dummy data for visualization if run not complete\n",
    "    our_scores = {\n",
    "        \"pass_at_1_accuracy\": 75.0,\n",
    "        \"evidence_quality\": 82.0,\n",
    "        \"subgoal_completion\": 88.0,\n",
    "        \"hallucination_rate\": 5.0,\n",
    "        \"context_efficiency\": 12.5\n",
    "    }\n",
    "\n",
    "# SOTA Baselines (Approximate from papers/leaderboards)\n",
    "baselines = {\n",
    "    \"FlowSearch\": {\n",
    "        \"pass_at_1_accuracy\": 68.0,\n",
    "        \"evidence_quality\": 75.0,\n",
    "        \"subgoal_completion\": 70.0,\n",
    "        \"hallucination_rate\": 12.0,\n",
    "        \"context_efficiency\": 10.0\n",
    "    },\n",
    "    \"RhinoInsight\": {\n",
    "        \"pass_at_1_accuracy\": 72.0,\n",
    "        \"evidence_quality\": 85.0,\n",
    "        \"subgoal_completion\": 65.0,\n",
    "        \"hallucination_rate\": 8.0,\n",
    "        \"context_efficiency\": 11.0\n",
    "    }\n",
    "}\n",
    "\n",
    "# Prepare DataFrame\n",
    "metrics = [\"pass_at_1_accuracy\", \"evidence_quality\", \"subgoal_completion\"]\n",
    "df_data = {\"Metric\": metrics}\n",
    "\n",
    "# Add Our Scores\n",
    "df_data[\"Our Agent\"] = [our_scores.get(m, 0) for m in metrics]\n",
    "\n",
    "# Add Baselines\n",
    "for name, scores in baselines.items():\n",
    "    df_data[name] = [scores.get(m, 0) for m in metrics]\n",
    "\n",
    "df = pd.DataFrame(df_data)\n",
    "df = df.set_index(\"Metric\")\n",
    "\n",
    "print(\"Performance Comparison Table:\")\n",
    "print(df)\n",
    "\n",
    "# Visualization\n",
    "try:\n",
    "    df.plot(kind=\"bar\", figsize=(10, 6))\n",
    "    plt.title(\"Deep Research Agent vs SOTA\")\n",
    "    plt.ylabel(\"Score (%)\")\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(axis='y')\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.show()\n",
    "except ImportError:\n",
    "    print(\"Matplotlib not available for plotting.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sota-comparison-todos",
   "metadata": {},
   "source": [
    "## 3. Pending Comparisons (TODO)\n",
    "\n",
    "### TODO: Update Feature Comparison Table\n",
    "- [ ] Add row for 'Recursive Research' once `research_subgraph` is live.\n",
    "- [ ] Add row for 'Structured Reading' once `content_reader` is live.\n",
    "\n",
    "### TODO: Live Data Integration\n",
    "- [ ] Replace dummy scores in cell above with real data loaded from `../results/benchmark_run.json` after a full `DeepResearch-Bench` run."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
