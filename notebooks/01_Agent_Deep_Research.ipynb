{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e841222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Universal Setup for Backend Environment\n",
    "import sys\n",
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def setup_environment():\n",
    "    \"\"\"Setup the environment by installing necessary dependencies and setting paths.\"\"\"\n",
    "    # Get the backend directory. If we are in 'backend', it is cwd.\n",
    "    backend_dir = Path.cwd()\n",
    "    if backend_dir.name != 'backend':\n",
    "        # Search for backend\n",
    "        if (backend_dir / 'backend').exists():\n",
    "             backend_dir = backend_dir / 'backend'\n",
    "        elif (backend_dir.parent / 'backend').exists():\n",
    "             backend_dir = backend_dir.parent / 'backend'\n",
    "    \n",
    "    # Add src to path if it exists (for 'from agent import ...' style)\n",
    "    src_dir = backend_dir / 'src'\n",
    "    if src_dir.exists():\n",
    "        if str(src_dir) not in sys.path:\n",
    "            sys.path.append(str(src_dir))\n",
    "            print(f\"âœ… Added {src_dir} to sys.path\")\n",
    "    \n",
    "    if str(backend_dir) not in sys.path:\n",
    "        sys.path.append(str(backend_dir))\n",
    "        \n",
    "    # Verify backend/agent can be imported\n",
    "    try:\n",
    "        import agent\n",
    "        print(\"âœ… Agent module found and imported.\")\n",
    "    except ImportError:\n",
    "        print(\"âŒ Agent module not found. Installing dependencies...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", str(backend_dir)])\n",
    "        print(\"âœ… Backend installed in editable mode.\")\n",
    "\n",
    "setup_environment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2481ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- COLAB SETUP START ---\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "\n",
    "if IN_COLAB:\n",
    "    # 1. Clone the repository\n",
    "    !git clone https://github.com/google-gemini/gemini-fullstack-langgraph-quickstart\n",
    "    %cd gemini-fullstack-langgraph-quickstart/backend\n",
    "\n",
    "    # 2. Prepare Environment (Resolving Conflicts)\n",
    "    import sys\n",
    "    print(\"Uninstalling conflicting pre-installed packages...\")\n",
    "    !pip uninstall -y google-ai-generativelanguage tensorflow grpcio-status\n",
    "\n",
    "    # Pre-install PyTorch Nightly if Python 3.13+ is detected\n",
    "    if sys.version_info >= (3, 13):\n",
    "        print(\"Detected Python 3.13+. Installing PyTorch Nightly...\")\n",
    "        !pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cpu\n",
    "\n",
    "    # 3. Install Backend\n",
    "    !pip install .\n",
    "\n",
    "    # 4. Set API Key\n",
    "    import os\n",
    "    from google.colab import userdata\n",
    "    try:\n",
    "        os.environ[\"GEMINI_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
    "    except:\n",
    "        print(\"Please enter your Gemini API Key:\")\n",
    "        os.environ[\"GEMINI_API_KEY\"] = input()\n",
    "# --- COLAB SETUP END ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83081f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MODEL CONFIGURATION ---\n",
    "# @title Select Gemini Model\n",
    "# @markdown Choose the Gemini model to use. Only Gemini 2.5 models are currently accessible via the API.\n",
    "\n",
    "MODEL_STRATEGY = \"Gemini 2.5 Flash (Recommended)\" # @param [\"Gemini 2.5 Flash (Recommended)\", \"Gemini 2.5 Flash-Lite (Fastest)\", \"Gemini 2.5 Pro (Best Quality)\"]\n",
    "\n",
    "import os\n",
    "\n",
    "# Map selection to model ID\n",
    "# Note: Gemini 1.5 and 2.0 models are deprecated/not accessible via this API\n",
    "if MODEL_STRATEGY == \"Gemini 2.5 Flash (Recommended)\":\n",
    "    SELECTED_MODEL = \"gemini-2.5-flash\"\n",
    "elif MODEL_STRATEGY == \"Gemini 2.5 Flash-Lite (Fastest)\":\n",
    "    SELECTED_MODEL = \"gemini-2.5-flash-lite\"\n",
    "elif MODEL_STRATEGY == \"Gemini 2.5 Pro (Best Quality)\":\n",
    "    SELECTED_MODEL = \"gemini-2.5-pro\"\n",
    "else:\n",
    "    # Default fallback\n",
    "    SELECTED_MODEL = \"gemini-2.5-flash\"\n",
    "\n",
    "print(f\"Selected Model: {SELECTED_MODEL}\")\n",
    "print(f\"Strategy: {MODEL_STRATEGY}\")\n",
    "\n",
    "# Set Environment Variables to override defaults\n",
    "os.environ[\"QUERY_GENERATOR_MODEL\"] = SELECTED_MODEL\n",
    "os.environ[\"REFLECTION_MODEL\"] = SELECTED_MODEL\n",
    "os.environ[\"ANSWER_MODEL\"] = SELECTED_MODEL\n",
    "os.environ[\"TOOLS_MODEL\"] = SELECTED_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f613de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MODEL VERIFICATION (Optional) ---\n",
    "# @title Verify Model Configuration\n",
    "# @markdown Run this cell to verify that your API key is configured correctly and the selected model is available.\n",
    "\n",
    "import os\n",
    "\n",
    "# Check if API key is set\n",
    "if \"GEMINI_API_KEY\" not in os.environ:\n",
    "    print(\"âš ï¸  GEMINI_API_KEY not found in environment variables!\")\n",
    "    print(\"   Please set it before proceeding:\")\n",
    "    print(\"   export GEMINI_API_KEY='your-api-key-here'\")\n",
    "else:\n",
    "    try:\n",
    "        from google import genai\n",
    "        \n",
    "        # Initialize the client\n",
    "        client = genai.Client(api_key=os.environ[\"GEMINI_API_KEY\"])\n",
    "        \n",
    "        # Test the selected model\n",
    "        print(f\"ðŸ§ª Testing model: {SELECTED_MODEL}\")\n",
    "        response = client.models.generate_content(\n",
    "            model=SELECTED_MODEL,\n",
    "            contents=\"Explain how AI works in a few words\"\n",
    "        )\n",
    "        \n",
    "        print(f\"âœ… Model verification successful!\")\n",
    "        print(f\"   Model: {SELECTED_MODEL}\")\n",
    "        print(f\"   Response: {response.text[:100]}...\")\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"âš ï¸  google-genai package not installed!\")\n",
    "        print(\"   Installing now...\")\n",
    "        import subprocess\n",
    "        import sys\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"google-genai\"])\n",
    "        print(\"âœ… Installed! Please re-run this cell.\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Model verification failed: {e}\")\n",
    "        print(f\"   This could mean:\")\n",
    "        print(f\"   - Invalid API key\")\n",
    "        print(f\"   - Model '{SELECTED_MODEL}' not available in your region\")\n",
    "        print(f\"   - Quota/billing issues (for experimental models)\")\n",
    "        print(f\"   - Network connectivity issues\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8e0b8e",
   "metadata": {},
   "source": [
    "# Deep Research Agent: Core Workflow\n",
    "\n",
    "This notebook demonstrates the core research workflow of the Deep Research Agent, including:\n",
    "1. Query Decomposition\n",
    "2. Web Search & RAG Ingestion\n",
    "3. Evidence Auditing & Verification\n",
    "4. Final Synthesis\n",
    "5. Artifact Export"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752ece1e",
   "metadata": {},
   "source": [
    "## 1. Setup & Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e67c664",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add backend/src to path so we can import modules\n",
    "sys.path.append(os.path.abspath(\"../backend/src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from agent.deep_search_agent import DeepSearchAgent\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from agent.configuration import Configuration\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d800b8b",
   "metadata": {},
   "source": [
    "## 2. Initialize Agent Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4df2436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLM\n",
    "# We use the SELECTED_MODEL from the config cell above\n",
    "model_name = os.environ.get(\"ANSWER_MODEL\", \"gemini-1.5-flash\")\n",
    "\n",
    "try:\n",
    "    print(f\"Initializing LLM with model: {model_name}\")\n",
    "    llm = ChatGoogleGenerativeAI(model=model_name, temperature=0)\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing LLM: {e}\")\n",
    "    # Fallback for testing\n",
    "    llm = None\n",
    "\n",
    "if llm:\n",
    "    # Initialize Agent\n",
    "    # Note: DeepSearchAgent internally uses the Configuration object which reads from env vars\n",
    "    agent = DeepSearchAgent(llm_client=llm)\n",
    "    print(\"Agent initialized successfully.\")\n",
    "else:\n",
    "    print(\"Failed to initialize Agent due to LLM error.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caad039",
   "metadata": {},
   "source": [
    "## 3. Single Query Research Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb409a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Latest advances in renewable energy storage\"\n",
    "print(f\"Starting research on: {query}\")\n",
    "\n",
    "if agent:\n",
    "    final_answer = agent.research(query)\n",
    "    print(\"\\n=== FINAL ANSWER ===\\n\")\n",
    "    print(final_answer)\n",
    "else:\n",
    "    print(\"Agent not initialized.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01709c70",
   "metadata": {},
   "source": [
    "## 4. RAG Verification Deep Dive\n",
    "\n",
    "Inspect the internal state of the RAG system to verify ingestion and retrieval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e9ffb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if agent:\n",
    "    # Inspect Doc Store\n",
    "    print(f\"Total documents indexed: {len(agent.rag.doc_store)}\")\n",
    "\n",
    "    # Sample a document\n",
    "    if len(agent.rag.doc_store) > 0:\n",
    "        doc_id = list(agent.rag.doc_store.keys())[0]\n",
    "        print(f\"\\nSample Document ({doc_id}):\")\n",
    "        print(agent.rag.doc_store[doc_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef81efe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if agent:\n",
    "    # Test Retrieval\n",
    "    test_query = \"battery cost reduction\"\n",
    "    results = agent.rag.retrieve(test_query, top_k=3)\n",
    "\n",
    "    print(f\"\\nRetrieval results for '{test_query}':\")\n",
    "    for doc, score in results:\n",
    "        print(f\"- [{score:.2f}] {doc.content[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6965873",
   "metadata": {},
   "source": [
    "## 5. Export Research Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1612afa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if agent:\n",
    "    state = agent.rag.export_state()\n",
    "    print(\"RAG State Export:\", state)\n",
    "\n",
    "    # Retrieve all docs for export\n",
    "    all_docs = agent.get_retrieved_documents()\n",
    "    print(f\"\\nPrepared {len(all_docs)} documents for export.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
