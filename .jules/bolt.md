## 2024-05-23 - Parallelizing Blocking LLM Calls
**Learning:** In synchronous LangGraph nodes, sequential LLM calls (e.g. for validation loop) can severely impact latency. Using `ThreadPoolExecutor` to parallelize these calls is highly effective, even if the underlying `RateLimiter` uses a lock, because the actual network IO (which is the slow part) happens *outside* the rate limiter lock.
**Action:** Always look for loops containing LLM calls in synchronous nodes and check if they can be parallelized using threads. Ensure the shared resources (like rate limiters) are thread-safe but do not serialize the actual IO.
